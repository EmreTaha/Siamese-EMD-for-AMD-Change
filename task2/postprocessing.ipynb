{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ecaa1f0a-3e6a-4877-9ed4-057f906cc329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from io import StringIO\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from utils import score_aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d623f432-9656-4114-b750-d57d4e8e6127",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_csv = \"/saved_models/experiment_1/predictions.csv\" # Path to the predictions file\n",
    "val_csv = \"/data_2/df_task2_val_challenge.csv\" # Provided validation set without labels during training phase \n",
    "val_gt = \"/data_2/task2_groundtruth.csv\" # Provided validation set with labels after the end of the developement phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fec4528f-8f1b-44f0-af02-080be65069eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(val_csv)\n",
    "pred_df = pd.read_csv(pred_csv)\n",
    "gt_df = pd.read_csv(val_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a141e772-afa7-476d-8593-35b576635e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'F1_score': 0.7203035060177917, 'Rk-correlation': 0.004134345683976752, 'Quadratic-weighted_Kappa': 0.013398849618260322, 'Specificity': 0.6666915643009497} 0.35113206640524464\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(val_df, pred_df, on='case')\n",
    "scores = score_aggregates(gt_df,merged_df)\n",
    "print(scores, np.array(list(scores.values())).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae445645-6698-4f56-bf82-095f215a113d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'F1_score': 0.6904761904761905, 'Rk-correlation': 0.0366900197207601, 'Quadratic-weighted_Kappa': 0.0658894556052877, 'Specificity': 0.6726727252179326} 0.3664320977550427\n"
     ]
    }
   ],
   "source": [
    "# Define the custom function\n",
    "def determine_new_column(row):\n",
    "    count = Counter(row.to_list())\n",
    "    # Get the score with the highest count\n",
    "    #print(count)\n",
    "    majority = count.most_common(1)[0][0]\n",
    "    unique_values = set(row)  \n",
    "    if unique_values == {1}:\n",
    "        return 1\n",
    "    elif unique_values == {0,1,2}:\n",
    "        return np.random.choice([0, 2])\n",
    "    elif unique_values == {0,1}:\n",
    "        return 0\n",
    "    elif unique_values == {1,2}:\n",
    "        return 2\n",
    "    else:\n",
    "        return majority\n",
    "        \n",
    "# Apply the custom function to the specific columns of interest\n",
    "merged_df['prediction'] = merged_df[['prediction_0', 'prediction_1', 'prediction_2']].apply(determine_new_column, axis=1)\n",
    "scores = score_aggregates(gt_df,merged_df)\n",
    "print(scores, np.array(list(scores.values())).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61c53a55-ec38-4b2b-894c-a1346dd03d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'F1_score': 0.7051282051282052, 'Rk-correlation': 0.20336175332438666, 'Quadratic-weighted_Kappa': 0.2159489269530026, 'Specificity': 0.7219411078684427} 0.46159499831850925\n"
     ]
    }
   ],
   "source": [
    "# Define a function to calculate the majority score based on the new rules\n",
    "def calculate_majority_score(scores):\n",
    "    total_scores = len(scores)\n",
    "    count_ones = (scores == 1).sum() \n",
    "    percentage_ones = count_ones / total_scores\n",
    "    \n",
    "    if percentage_ones >= 0.80:\n",
    "        return 1\n",
    "    else:\n",
    "        # Calculate majority score between 0 and 2\n",
    "        count = Counter(scores)\n",
    "        # Filter out count of 1\n",
    "        count.pop(1, None)\n",
    "        if count:\n",
    "            return count.most_common(1)[0][0]\n",
    "        else:\n",
    "            # This case should not normally occur since it means there are no 0s or 2s\n",
    "            return np.random.choice([0, 2])\n",
    "val_df = pd.read_csv(val_csv)\n",
    "pred_df = pd.read_csv(pred_csv+\"/predictions.csv\")\n",
    "merged_df = pd.merge(val_df, pred_df, on='case')\n",
    "merged_df['prediction'] = merged_df[['prediction_0', 'prediction_1', 'prediction_2']].apply(determine_new_column, axis=1)\n",
    "# Group by 'ID' and calculate the majority score for each group\n",
    "majority_scores = merged_df.groupby('LOCALIZER')['prediction'].apply(calculate_majority_score).reset_index()\n",
    "\n",
    "# Rename the column to 'Majority_Score'\n",
    "majority_scores.columns = ['LOCALIZER', 'Majority_Score']\n",
    "\n",
    "# Merge the majority scores back to the original DataFrame\n",
    "merged_df = pd.merge(merged_df, majority_scores, on='LOCALIZER')\n",
    "\n",
    "# Replace the original 'Score' with the 'Majority_Score'\n",
    "merged_df['prediction'] = merged_df['Majority_Score']\n",
    "\n",
    "# Drop the 'Majority_Score' column as it's no longer needed\n",
    "merged_df = merged_df.drop(columns=['Majority_Score'])\n",
    "scores = score_aggregates(gt_df,merged_df)\n",
    "print(scores, np.array(list(scores.values())).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e7eeeef7-90f1-46c7-a5b0-b2924d77c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(pred_csv+'/predv2.csv',index=False)\n",
    "zip = zipfile.ZipFile(pred_csv+'/predv7.zip', \"w\", zipfile.ZIP_DEFLATED)\n",
    "zip.write(pred_csv+'/predv7.csv', arcname='/predv7.csv')\n",
    "zip.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
